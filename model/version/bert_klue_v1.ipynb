{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63b2b204",
   "metadata": {
    "id": "63b2b204"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from transformers import TFBertModel, BertConfig, AutoTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52db125b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52db125b",
    "outputId": "fdb6cc97-1e71-4b0f-9545-474c226034c8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 1\n",
      "GPU Details: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# 사용 가능한 GPU 목록 확인\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available:\", len(gpus))\n",
    "print(\"GPU Details:\", gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710de7f6",
   "metadata": {
    "id": "710de7f6"
   },
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d100970",
   "metadata": {
    "id": "8d100970"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv', index_col=0) # 캐글 데이터\n",
    "gen_df = pd.read_csv('gen_data_final998.csv', index_col=0) # 합성데이터\n",
    "class_dict = {'협박 대화': 0, '갈취 대화':1, '직장 내 괴롭힘 대화':2, '기타 괴롭힘 대화':3, '일반 대화':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e3e044f",
   "metadata": {
    "id": "0e3e044f"
   },
   "outputs": [],
   "source": [
    "gen_df['topic'] = '일반 대화'\n",
    "gen_df = gen_df.rename(columns={'topic':'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ea90555",
   "metadata": {
    "id": "8ea90555"
   },
   "outputs": [],
   "source": [
    "data_df = pd.concat([train_df, gen_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d59613",
   "metadata": {
    "id": "d4d59613"
   },
   "outputs": [],
   "source": [
    "data_df['class'] = data_df['class'].apply(lambda x: class_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29cee36d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29cee36d",
    "outputId": "fb3041d0-60dc-4ebc-edc9-cb9e247b2906"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 데이터의 최대 길이를 구함\n",
    "data_len = [len(x.split()) for x in data_df['conversation']]\n",
    "MAX_LEN = max(data_len)\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "817d48f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "817d48f9",
    "outputId": "82fa1f66-0e74-4258-df6f-ec8f8d6bcf9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4948, 4948)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(data_df['class'])\n",
    "len(data_df['conversation']), len(labels) # 대화 , labels 갯수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7477effd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7477effd",
    "outputId": "b55608f0-605b-46e2-bebf-61bfedc92c3a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6538c3a",
   "metadata": {
    "id": "c6538c3a"
   },
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c4c8d14",
   "metadata": {
    "id": "9c4c8d14"
   },
   "outputs": [],
   "source": [
    "model_name = \"klue/bert-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59c652b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307,
     "referenced_widgets": [
      "e6b462fac7bc422098f19700df0953e3",
      "cfc650a8893d49ff8c87fcd0037869b1",
      "a383b025ca9741d6b40b62265df5a7b8",
      "3a4a933880f94978b17785f7b7af78dd",
      "be026d846de545f38b8887d06c94d08f",
      "f98b75af6ef845ad90c2653307209203",
      "49be5726f8564b5ca234a287a41a37a6",
      "bd749f0494fb490c9c9b819679b2f176",
      "8bc120c8d7174bc89ddddbb8adcf25dd",
      "006ff2ba61d54d8d9b5cc252d630825c",
      "8f6ca84077d2463dbb25a4f3d800df96",
      "fde017a4180e45af9c20beeeefd83b41",
      "bf21df3b8a3e4f9aa9b000e5ce7d7b87",
      "35808deb0bae4a92a2cdafc7e572311c",
      "b2d80aa036104eafbc4350c2a1d4b99e",
      "491a883e994f4018ab2a758bd04ab12c",
      "67803bdf66b84bf79c387ee8704c2e99",
      "e0c0935461554fe2a5124b7b10d0c54a",
      "65dbf1dc283b443893f165cc4a355d1b",
      "b9e5f2ff84624ad2a90bcf14c2c02f25",
      "357a33591386428690b7c94d1a68355e",
      "b7e1d2bf212f4ca69ef7377900454025",
      "261ee7a476dd4d548d73068fd0983202",
      "074ec061f083421bbb7de8ed8b1e086f",
      "bcdb914d24c842998f3722e43ecdc547",
      "9ea5cf842b8549fa88eacab39c19c1e5",
      "bd9da940cf6841a39531c0386decb66d",
      "bf36e94502ac4515acb820a8dd42ad23",
      "9a9c12ca580c4d109a7cd17cfa8df87f",
      "f1237cb908cd4b409fb8b789338c9832",
      "3b245251c363476f87d7b9c7a217ccf5",
      "e6e49704e01a433cbc7b13264cfef808",
      "80038a78c5744fdf8cbee8dbcf8a95fc",
      "030409c1f9874fb29b953176e272c258",
      "7ceb8212927e4cc4a47150c3ce51ad1e",
      "18a41ae88e77414b89412405a98ab995",
      "900311ea03384c44a5d1627faed43124",
      "dd27771728d046e0831a9b6fb48cf792",
      "6b321e24fb274414aff0e84d1722d2f9",
      "ea5fd02e3f1041b68882065f2cfe0905",
      "a2eb0d7b89a249b084e2110cd0e4f296",
      "bad54551d44e46e48715eeae65ee02ae",
      "7eb8dc13b7d84abb8d306e0f430e48b2",
      "bd2cbd0a165e4a89ab1d3457f23ae57b",
      "2f0871889501435bbd07a9d42ed6741f",
      "67e52c67880046b9995a0905c6579a70",
      "743ce1cad95b4f6589e9f9708e677973",
      "333447e21eff472bb0b8324c34f46fa4",
      "634ee7b79bf84819b373edc7d6285786",
      "65217bc96e9247a78c8c61cca56f3714",
      "85b761130c3f439eae9ed1fe1dbdcebf",
      "316d1a12986247e1aebbf820f7cbf4e5",
      "49f2fa70c026434a8f6fa29ed41f7128",
      "7f6ee830122a4e1f9cc6bfac954121e8",
      "d47d2d36f3b34ffe9163feaf120a23fa"
     ]
    },
    "id": "59c652b4",
    "outputId": "3303e2bb-a0e8-4fd3-8e71-b25a4edb829c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b462fac7bc422098f19700df0953e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde017a4180e45af9c20beeeefd83b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261ee7a476dd4d548d73068fd0983202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030409c1f9874fb29b953176e272c258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0871889501435bbd07a9d42ed6741f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b2103b4",
   "metadata": {
    "id": "0b2103b4"
   },
   "outputs": [],
   "source": [
    "token_data = tokenizer(\n",
    "    list(data_df['conversation']),\n",
    "    padding='max_length', # 자동으로 최대 길이로 패딩해줌\n",
    "    truncation=True, # 모델이 감당 가능한 최대 길이 초과하면 자름\n",
    "    return_tensors='np'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2098ff2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2098ff2",
    "outputId": "92480a6a-8bb9-4e6f-c7f6-8f3b47b72aff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토크나이저 후 데이터 내 최대 시퀀스 길이: 512\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(seq) for seq in token_data['input_ids']]\n",
    "print(f\"토크나이저 후 데이터 내 최대 시퀀스 길이: {max(lengths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a321a3e9",
   "metadata": {
    "id": "a321a3e9"
   },
   "source": [
    "### 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "836d6c53",
   "metadata": {
    "id": "836d6c53"
   },
   "outputs": [],
   "source": [
    "num_samples = len(data_df) # 전체 샘플 갯수\n",
    "indices = np.arange(num_samples) # 인덱스 생성\n",
    "\n",
    "train_indices, val_indices = train_test_split( # 인덱스를 8대2로 나눔\n",
    "    indices,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels # stratify에는 target값으로 class 비율 일정하게 셔플\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "857142ba",
   "metadata": {
    "id": "857142ba"
   },
   "outputs": [],
   "source": [
    "train_inputs = {key: tf.gather(train, train_indices) for key, train in token_data.items()}\n",
    "val_inputs = {key: tf.gather(val, val_indices) for key, val in token_data.items()}\n",
    "\n",
    "# 레이블도 동일한 인덱스로 선택\n",
    "train_labels = tf.gather(labels, train_indices)\n",
    "val_labels = tf.gather(labels, val_indices)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_inputs, train_labels))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000).batch(8) # 셔플 및 배치\n",
    "\n",
    "# 예시: 검증 데이터셋 생성\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_inputs, val_labels))\n",
    "val_dataset = val_dataset.batch(8) # 검증 데이터는 보통 셔플하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ea24a6e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ea24a6e",
    "outputId": "621ed918-bacc-4547-863a-f99afbebabdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'input_ids': <tf.Tensor: shape=(8, 512), dtype=int64, numpy=\n",
      "array([[    2,  1396,  1507, ...,     0,     0,     0],\n",
      "       [    2, 11683,  1269, ...,     0,     0,     0],\n",
      "       [    2,  7082,  2059, ...,     0,     0,     0],\n",
      "       ...,\n",
      "       [    2,  1396,  7171, ...,     0,     0,     0],\n",
      "       [    2,  1535,  2259, ...,     0,     0,     0],\n",
      "       [    2,  1370,    18, ...,     0,     0,     0]])>, 'token_type_ids': <tf.Tensor: shape=(8, 512), dtype=int64, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]])>, 'attention_mask': <tf.Tensor: shape=(8, 512), dtype=int64, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]])>}, <tf.Tensor: shape=(8,), dtype=int32, numpy=array([2, 0, 1, 0, 1, 0, 4, 2], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataset:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8dc60aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198,
     "referenced_widgets": [
      "96f0dfa10dbe46ce9512353957be6211",
      "e948de52e67d4f158115831f4dd40c7d",
      "27ce7236e3744d6cad45711e6e756ded",
      "356c2564d00a40b191b8769038d8f752",
      "ef3915f634144a68a5e94617a3531cea",
      "2959908448ab4240ae9d1aa19b152067",
      "bf60cc90a3f34e278bcb643af3337dd7",
      "60dc74568c334d91aadb13fc2288fe0a",
      "d7ef1ceb5dc64e768e37f990ff8a6094",
      "0af67393b3894f60a18894f9a2c8c85e",
      "9e8fd25f634e44a482b5deac9e0f5fbe"
     ]
    },
    "id": "f8dc60aa",
    "outputId": "8f5c5a5b-93e6-4a47-d5e8-4cf4acc39278"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f0dfa10dbe46ce9512353957be6211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 사전학습된 klue 모델 불러오기\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=num_classes, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4284ff45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4284ff45",
    "outputId": "c9bd3828-c0a8-45f5-e15f-e63702c8a6e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFSequenceClassifierOutput(loss=None, logits=<tf.Tensor: shape=(1, 5), dtype=float32, numpy=\n",
       "array([[-0.23880652,  0.20831637,  0.0197846 ,  0.05509594,  0.09337355]],\n",
       "      dtype=float32)>, hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 더미 입력으로 모델 동작하는지 빌드\n",
    "dummy_input = tokenizer(\n",
    "    [\"더미 텍스트\"],\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "model(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39dcc199",
   "metadata": {
    "id": "39dcc199"
   },
   "outputs": [],
   "source": [
    "model.bert.trainable = False\n",
    "model.classifier.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dd5d051",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2dd5d051",
    "outputId": "0cc72a98-f371-4983-c746-a79ffb40e2c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer bert is trainable: False\n",
      "Layer dropout_37 is trainable: True\n",
      "Layer classifier is trainable: True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(f\"Layer {layer.name} is trainable: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e884b07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e884b07",
    "outputId": "a8a29ccb-e042-482a-c3d1-bb27ddadcb02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  110617344 \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  3845      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110621189 (421.99 MB)\n",
      "Trainable params: 3845 (15.02 KB)\n",
      "Non-trainable params: 110617344 (421.97 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ccae7c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ccae7c6",
    "outputId": "6ab04f4b-cf4c-4a50-f151-1b1b44264ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer bert is trainable: False\n",
      "Layer dropout_37 is trainable: True\n",
      "Layer classifier is trainable: True\n"
     ]
    }
   ],
   "source": [
    "# bert 층 동결하고 classifier 부분만 사용\n",
    "for layer in model.layers:\n",
    "    print(f\"Layer {layer.name} is trainable: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff99dc7a",
   "metadata": {
    "id": "ff99dc7a"
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=5e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# 10. 모델 컴파일\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12aa1734",
   "metadata": {
    "id": "12aa1734"
   },
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    restore_best_weights=True,\n",
    "    patience=2)\n",
    "\n",
    "# ModelCheckpoint 콜백 수정\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    filepath='klue_weight.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af80d85e",
   "metadata": {
    "id": "af80d85e"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bee0968f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bee0968f",
    "outputId": "5ccd46bd-8381-442c-ccca-8a5b701c7b9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "495/495 [==============================] - 259s 467ms/step - loss: 1.4178 - accuracy: 0.4763 - val_loss: 1.2542 - val_accuracy: 0.6283\n",
      "Epoch 2/50\n",
      "495/495 [==============================] - 270s 546ms/step - loss: 1.1727 - accuracy: 0.6483 - val_loss: 1.0744 - val_accuracy: 0.6667\n",
      "Epoch 3/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 1.0380 - accuracy: 0.6882 - val_loss: 0.9676 - val_accuracy: 0.7030\n",
      "Epoch 4/50\n",
      "495/495 [==============================] - 270s 546ms/step - loss: 0.9417 - accuracy: 0.7110 - val_loss: 0.8874 - val_accuracy: 0.7141\n",
      "Epoch 5/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.8728 - accuracy: 0.7322 - val_loss: 0.8305 - val_accuracy: 0.7263\n",
      "Epoch 6/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.8202 - accuracy: 0.7484 - val_loss: 0.7893 - val_accuracy: 0.7293\n",
      "Epoch 7/50\n",
      "495/495 [==============================] - 230s 465ms/step - loss: 0.7805 - accuracy: 0.7491 - val_loss: 0.7444 - val_accuracy: 0.7485\n",
      "Epoch 8/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.7467 - accuracy: 0.7587 - val_loss: 0.7163 - val_accuracy: 0.7556\n",
      "Epoch 9/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.7153 - accuracy: 0.7650 - val_loss: 0.6889 - val_accuracy: 0.7667\n",
      "Epoch 10/50\n",
      "495/495 [==============================] - 231s 468ms/step - loss: 0.6881 - accuracy: 0.7817 - val_loss: 0.6701 - val_accuracy: 0.7576\n",
      "Epoch 11/50\n",
      "495/495 [==============================] - 231s 466ms/step - loss: 0.6667 - accuracy: 0.7852 - val_loss: 0.6488 - val_accuracy: 0.7798\n",
      "Epoch 12/50\n",
      "495/495 [==============================] - 231s 466ms/step - loss: 0.6530 - accuracy: 0.7885 - val_loss: 0.6326 - val_accuracy: 0.7758\n",
      "Epoch 13/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.6352 - accuracy: 0.7858 - val_loss: 0.6203 - val_accuracy: 0.7818\n",
      "Epoch 14/50\n",
      "495/495 [==============================] - 231s 468ms/step - loss: 0.6185 - accuracy: 0.7948 - val_loss: 0.6117 - val_accuracy: 0.7768\n",
      "Epoch 15/50\n",
      "495/495 [==============================] - 230s 466ms/step - loss: 0.6204 - accuracy: 0.7908 - val_loss: 0.5963 - val_accuracy: 0.7889\n",
      "Epoch 16/50\n",
      "495/495 [==============================] - 270s 545ms/step - loss: 0.6010 - accuracy: 0.7976 - val_loss: 0.5850 - val_accuracy: 0.7939\n",
      "Epoch 17/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.5884 - accuracy: 0.8047 - val_loss: 0.5779 - val_accuracy: 0.7919\n",
      "Epoch 18/50\n",
      "495/495 [==============================] - 270s 547ms/step - loss: 0.5812 - accuracy: 0.8060 - val_loss: 0.5705 - val_accuracy: 0.7939\n",
      "Epoch 19/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.5756 - accuracy: 0.7961 - val_loss: 0.5603 - val_accuracy: 0.7949\n",
      "Epoch 20/50\n",
      "495/495 [==============================] - 230s 466ms/step - loss: 0.5669 - accuracy: 0.8057 - val_loss: 0.5553 - val_accuracy: 0.7990\n",
      "Epoch 21/50\n",
      "495/495 [==============================] - 269s 545ms/step - loss: 0.5598 - accuracy: 0.8110 - val_loss: 0.5491 - val_accuracy: 0.8030\n",
      "Epoch 22/50\n",
      "495/495 [==============================] - 231s 468ms/step - loss: 0.5530 - accuracy: 0.8067 - val_loss: 0.5407 - val_accuracy: 0.8020\n",
      "Epoch 23/50\n",
      "495/495 [==============================] - 231s 468ms/step - loss: 0.5471 - accuracy: 0.8047 - val_loss: 0.5390 - val_accuracy: 0.8051\n",
      "Epoch 24/50\n",
      "495/495 [==============================] - 231s 466ms/step - loss: 0.5420 - accuracy: 0.8209 - val_loss: 0.5299 - val_accuracy: 0.8051\n",
      "Epoch 25/50\n",
      "495/495 [==============================] - 230s 465ms/step - loss: 0.5340 - accuracy: 0.8168 - val_loss: 0.5256 - val_accuracy: 0.8030\n",
      "Epoch 26/50\n",
      "495/495 [==============================] - 230s 465ms/step - loss: 0.5271 - accuracy: 0.8199 - val_loss: 0.5264 - val_accuracy: 0.8081\n",
      "Epoch 27/50\n",
      "495/495 [==============================] - 230s 465ms/step - loss: 0.5254 - accuracy: 0.8191 - val_loss: 0.5178 - val_accuracy: 0.8071\n",
      "Epoch 28/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.5210 - accuracy: 0.8244 - val_loss: 0.5142 - val_accuracy: 0.8071\n",
      "Epoch 29/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.5098 - accuracy: 0.8272 - val_loss: 0.5095 - val_accuracy: 0.8111\n",
      "Epoch 30/50\n",
      "495/495 [==============================] - 231s 466ms/step - loss: 0.5190 - accuracy: 0.8262 - val_loss: 0.5087 - val_accuracy: 0.8091\n",
      "Epoch 31/50\n",
      "495/495 [==============================] - 270s 547ms/step - loss: 0.5115 - accuracy: 0.8249 - val_loss: 0.5022 - val_accuracy: 0.8152\n",
      "Epoch 32/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.5137 - accuracy: 0.8209 - val_loss: 0.5008 - val_accuracy: 0.8141\n",
      "Epoch 33/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.5054 - accuracy: 0.8226 - val_loss: 0.5003 - val_accuracy: 0.8172\n",
      "Epoch 34/50\n",
      "495/495 [==============================] - 231s 466ms/step - loss: 0.5111 - accuracy: 0.8257 - val_loss: 0.4964 - val_accuracy: 0.8131\n",
      "Epoch 35/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.5044 - accuracy: 0.8216 - val_loss: 0.4931 - val_accuracy: 0.8162\n",
      "Epoch 36/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.4960 - accuracy: 0.8284 - val_loss: 0.4950 - val_accuracy: 0.8202\n",
      "Epoch 37/50\n",
      "495/495 [==============================] - 231s 466ms/step - loss: 0.5010 - accuracy: 0.8231 - val_loss: 0.4873 - val_accuracy: 0.8212\n",
      "Epoch 38/50\n",
      "495/495 [==============================] - 231s 466ms/step - loss: 0.4855 - accuracy: 0.8355 - val_loss: 0.4864 - val_accuracy: 0.8232\n",
      "Epoch 39/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.4932 - accuracy: 0.8244 - val_loss: 0.4844 - val_accuracy: 0.8212\n",
      "Epoch 40/50\n",
      "495/495 [==============================] - 232s 468ms/step - loss: 0.4900 - accuracy: 0.8284 - val_loss: 0.4828 - val_accuracy: 0.8182\n",
      "Epoch 41/50\n",
      "495/495 [==============================] - 230s 466ms/step - loss: 0.4872 - accuracy: 0.8330 - val_loss: 0.4782 - val_accuracy: 0.8263\n",
      "Epoch 42/50\n",
      "495/495 [==============================] - 270s 546ms/step - loss: 0.4766 - accuracy: 0.8340 - val_loss: 0.4782 - val_accuracy: 0.8192\n",
      "Epoch 43/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.4761 - accuracy: 0.8322 - val_loss: 0.4752 - val_accuracy: 0.8242\n",
      "Epoch 44/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.4761 - accuracy: 0.8310 - val_loss: 0.4751 - val_accuracy: 0.8202\n",
      "Epoch 45/50\n",
      "495/495 [==============================] - 230s 465ms/step - loss: 0.4705 - accuracy: 0.8335 - val_loss: 0.4705 - val_accuracy: 0.8273\n",
      "Epoch 46/50\n",
      "495/495 [==============================] - 231s 467ms/step - loss: 0.4778 - accuracy: 0.8274 - val_loss: 0.4715 - val_accuracy: 0.8232\n",
      "Epoch 47/50\n",
      "495/495 [==============================] - 231s 466ms/step - loss: 0.4688 - accuracy: 0.8360 - val_loss: 0.4685 - val_accuracy: 0.8222\n",
      "Epoch 48/50\n",
      "495/495 [==============================] - 230s 466ms/step - loss: 0.4636 - accuracy: 0.8408 - val_loss: 0.4673 - val_accuracy: 0.8253\n",
      "Epoch 49/50\n",
      "495/495 [==============================] - 230s 466ms/step - loss: 0.4705 - accuracy: 0.8363 - val_loss: 0.4672 - val_accuracy: 0.8293\n",
      "Epoch 50/50\n",
      "495/495 [==============================] - 230s 465ms/step - loss: 0.4749 - accuracy: 0.8312 - val_loss: 0.4633 - val_accuracy: 0.8293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7d457bdbe290>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping_cb]\n",
    "    # callbacks=[early_stopping_cb, model_checkpoint_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kf_GG-jvXVcz",
   "metadata": {
    "id": "Kf_GG-jvXVcz"
   },
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors='tf', padding='max_length', truncation=True)\n",
    "    logits = model(inputs).logits\n",
    "    return int(tf.argmax(logits, axis=1).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NRNZapWIXLcf",
   "metadata": {
    "id": "NRNZapWIXLcf"
   },
   "outputs": [],
   "source": [
    "submission['target'] = test_df['text'].apply(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bef022c",
   "metadata": {
    "id": "0bef022c"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('bert_klue_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6954ab8",
   "metadata": {
    "id": "b6954ab8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d830dc",
   "metadata": {
    "id": "28d830dc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
