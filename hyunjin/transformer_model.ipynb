{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0575f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, GlobalMaxPool1D, LayerNormalization, Dropout, MultiHeadAttention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. 데이터 준비\n",
    "df = pd.read_csv('train_merged.csv')\n",
    "df = df.rename(columns={'class': 'target'})\n",
    "\n",
    "# 레이블 인코딩\n",
    "le = LabelEncoder()\n",
    "df['target'] = le.fit_transform(df['target'])\n",
    "\n",
    "# 데이터 분할\n",
    "X = df['conversation'].astype(str).values\n",
    "y = df['target'].values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 2. 텍스트 벡터화\n",
    "VOCAB_SIZE = 20000\n",
    "MAX_LEN = 128\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_LEN\n",
    ")\n",
    "vectorize_layer.adapt(X_train)\n",
    "\n",
    "# 3. 포지셔널 인코딩 클래스\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_len, embed_dim):\n",
    "        super().__init__()\n",
    "        self.pos_encoding = self.positional_encoding(max_len, embed_dim)\n",
    "\n",
    "    def get_angles(self, position, i, embed_dim):\n",
    "        angles = 1 / tf.pow(10000.0, (2 * (i // 2)) / tf.cast(embed_dim, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, max_len, embed_dim):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(max_len, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(embed_dim, dtype=tf.float32)[tf.newaxis, :],\n",
    "            embed_dim=embed_dim\n",
    "        )\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        return inputs + self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "# 4. 트랜스포머 디코더 블록\n",
    "class TransformerDecoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(num_heads, embed_dim)\n",
    "        self.enc_attn = MultiHeadAttention(num_heads, embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(embed_dim)\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        self.dropout3 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, enc_output, training=False):\n",
    "        attn1 = self.self_attn(inputs, inputs, use_causal_mask=True)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn1)\n",
    "        \n",
    "        attn2 = self.enc_attn(out1, enc_output)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(out1 + attn2)\n",
    "        \n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        return self.layernorm3(out2 + ffn_output)\n",
    "\n",
    "# 5. 모델 구성 함수\n",
    "def build_transformer_model():\n",
    "    inputs = Input(shape=(1,), dtype=tf.string)\n",
    "    \n",
    "    # 벡터화\n",
    "    x = vectorize_layer(inputs)\n",
    "    x = Embedding(VOCAB_SIZE, 128)(x)\n",
    "    x = PositionalEncoding(MAX_LEN, 128)(x)\n",
    "    \n",
    "    # 인코더\n",
    "    enc_output = None\n",
    "    for _ in range(2):\n",
    "        x = MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = LayerNormalization(epsilon=1e-6)(x)\n",
    "        enc_output = x\n",
    "    \n",
    "    # 디코더\n",
    "    dec_input = x\n",
    "    for _ in range(2):\n",
    "        dec_input = TransformerDecoderBlock(128, 4, 256)(dec_input, enc_output)\n",
    "    \n",
    "    # 출력\n",
    "    x = GlobalMaxPool1D()(dec_input)\n",
    "    outputs = Dense(len(le.classes_), activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', \n",
    "                 loss='sparse_categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 6. 모델 생성\n",
    "model = build_transformer_model()\n",
    "\n",
    "# 7. F1 콜백\n",
    "class F1Callback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, X_val, y_val):\n",
    "        super().__init__()\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = self.model.predict(self.X_val).argmax(axis=1)\n",
    "        f1 = f1_score(self.y_val, y_pred, average='macro')\n",
    "        print(f'\\nVal F1: {f1:.4f}')\n",
    "\n",
    "# 8. 학습 실행\n",
    "X_train = tf.convert_to_tensor(X_train, dtype=tf.string)\n",
    "X_val = tf.convert_to_tensor(X_val, dtype=tf.string)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
    "y_val = tf.convert_to_tensor(y_val, dtype=tf.int32)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks=[F1Callback(X_val, y_val.numpy())]  # y_val을 numpy 배열로 변환\n",
    ")\n",
    "\n",
    "# 9. 시각화 코드 (수정)\n",
    "def plot_metrics(history):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Loss\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Val')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(history)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
