{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53984e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv('train.csv')\n",
    "# 컬럼명 변경\n",
    "df = df.rename(columns={'id': 'idx', 'label': 'target'})\n",
    "\n",
    "# 데이터 선택\n",
    "X = df['conversation']\n",
    "y = df['target']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 벡터화\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_val_vec = vectorizer.transform(X_val)\n",
    "\n",
    "# 모델 학습\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred = model.predict(X_val_vec)\n",
    "\n",
    "# 정확도\n",
    "print('Validation Accuracy:', accuracy_score(y_val, y_pred))\n",
    "\n",
    "# F-1 스코어 (macro 평균)\n",
    "f1_macro = f1_score(y_val, y_pred, average='macro')\n",
    "print('Validation F1 Macro:', f1_macro)\n",
    "\n",
    "# 클래스별 F-1 스코어\n",
    "f1_per_class = f1_score(y_val, y_pred, average=None)\n",
    "print('F1 per class:')\n",
    "for idx, score in enumerate(f1_per_class):\n",
    "    print(f'Class {idx}: {score:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6a89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 데이터 준비\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# 컬럼명 변경\n",
    "df = df.rename(columns={'id': 'idx', 'label': 'target'})\n",
    "\n",
    "X = df['conversation']\n",
    "y = df['target']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "# 1. 텍스트 벡터화\n",
    "VOCAB_SIZE = 20000\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=128\n",
    ")\n",
    "vectorize_layer.adapt(X_train)\n",
    "\n",
    "# 2. 트랜스포머 블록\n",
    "def transformer_encoder(inputs, head_size=64, num_heads=4, ff_dim=128):\n",
    "    # Multi-head attention\n",
    "    x = tf.keras.layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads\n",
    "    )(inputs, inputs)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
    "\n",
    "    # Feed forward\n",
    "    y = tf.keras.layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    y = tf.keras.layers.Dense(inputs.shape[-1])(y)\n",
    "    y = tf.keras.layers.Dropout(0.3)(y)\n",
    "    return tf.keras.layers.LayerNormalization(epsilon=1e-6)(x + y)\n",
    "\n",
    "# 3. 모델 구성\n",
    "inputs = Input(shape=(1,), dtype=tf.string)\n",
    "x = vectorize_layer(inputs)\n",
    "x = tf.keras.layers.Embedding(VOCAB_SIZE, 128)(x)\n",
    "x = transformer_encoder(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "outputs = Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 4. F1-score 콜백\n",
    "class F1Callback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred = model.predict(X_val).argmax(axis=1)\n",
    "        f1 = f1_score(y_val, y_pred, average='macro')\n",
    "        print(f'\\nVal F1: {f1:.4f}')\n",
    "\n",
    "# 5. 학습\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    callbacks=[F1Callback()]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9529b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# 1. train 폴더 안의 모든 .tsv 파일 경로 가져오기\n",
    "file_list = glob.glob('train/*.tsv')  # 또는 './train/*.tsv'\n",
    "\n",
    "# 2. 각 파일을 DataFrame으로 읽어 리스트에 저장\n",
    "dfs = [pd.read_csv(f, sep='\\t') for f in file_list]\n",
    "\n",
    "# 3. 데이터프레임 합치기\n",
    "merged = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# 4. CSV로 저장\n",
    "merged.to_csv('train_merged.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c938d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
